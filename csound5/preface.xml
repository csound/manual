<preface id="csound5preface">

<author><firstname>Barry</firstname><surname>Vercoe</surname></author>

<para>
Realizing music by digital computer involves synthesizing audio signals with discrete points or
samples representative of continuous waveforms. There are many ways to do this, each affording
a different manner of control. Direct synthesis generates waveforms by sampling a stored function
representing a single cycle; additive synthesis generates the many partials of a complex tone, each
with its own loudness envelope; subtractive synthesis begins with a complex tone and filters it.
Non-linear synthesis uses frequency modulation and waveshaping to give simple signals complex
characteristics, while sampling and storage of a natural sound allows it to be used at will.
</para>

<para>
Since comprehensive moment-by-mmoment specification of sound can be tedious, control is gained
in two ways: 1) from the instruments in an orchestra, and 2) from the events within a score. An
orchestra is really a computer program that can produce sound, while a score is a body of data
which that program can react to. Whether a rise-time characteristic is a fixed constant in an
instrument, or a variable of each note in the score, depends on how the user wants to control it.
The instruments in a Csound orchestra are defined in a simple syntax that invokes complex audio
processing routines. A score passed to this orchestra contains numerically coded pitch and control
information, in standard numeric score format. Although many users are content with this format,
higher level score processing languages are often convenient.
</para>

<para>
The programs making up the Csound system have a long history of development, beginning with the
Music 4 program written at Bell Telephone Laboratories in the early 1960s by Max Mathews. That
initiated the stored table concept and much of the terminology that has since enabled computer
music researchers to communicate. Valuable additions were made at Princeton by the late Godfrey
Winham in Music 4B; my own Music 360 (1968) was very indebted to his work. With Music 11
(1973) I took a different tack: the two distinct networks of control and audio signal processing
stemmed from my intensive involvement in the preceding years in hardware synthesizer concepts
and design. This division has been retained in Csound. Because it is written entirely in C, Csound
is easily installed on any machine running Unix or C. At MIT it runs on VAX/DECstations under
Ultrix 4.2, on SUNs under OS 4.1, SGIs under 5.0, on IBM PCs under DOS 6.2 and Windows
3.1, and on the AppleMacintosh under ThinkC 5.0. With this single language for defining the
audio signal processing, and portable audio formats like AIFF andWAV, users can move easily
from machine to machine.
</para>

<para>
The 1991 version added phase vocoder, FOF, and spectral data types. 1992 saw MIDI converter
and control units, enabling Csound to be run from MIDI score-files and external keyboards. In
1994 the sound analysis programs (lpc, pvoc) were integrated into the main load module, enabling
all Csound processing to be run from a single executable, and Cscore could pass scores directly
to the orchestra for iterative performance. The 1995 release introduced an expanded MIDI set
with MIDI-based linseg, butterworth filters, granular synthesis, and an improved spectral-based
pitch tracker. Of special importance was the addition of run-time event generating tools (Cscore
and MIDI) allowing run-time sensing and response setups that enable interactive composition and
experiment. It appeared that real-time software synthesis was now showing some real promise.
</para>

</preface>
